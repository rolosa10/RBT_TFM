{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f319c3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c147157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import axes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9933b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ff888",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e59339",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_numbers_variables = {0:'right_shoulder',\n",
    "                             1:'right_elbow',\n",
    "                             2:'right_wrist',\n",
    "                             3:'left_shoulder',\n",
    "                             4:'left_elbow',\n",
    "                             5:'left_wrist'}\n",
    "\n",
    "\n",
    "columns_df_2D_interest = ['RightShoulder_2D','RightShoulder_2D.1',\n",
    "                          'RightElbow_2D', 'RightElbow_2D.1',\n",
    "                          'RightHand_2D','RightHand_2D.1',\n",
    "                          'LeftShoulder_2D','LeftShoulder_2D.1',\n",
    "                          'LeftElbow_2D', 'LeftElbow_2D.1', \n",
    "                          'LeftHand_2D','LeftHand_2D.1']\n",
    "\n",
    "columns_df_3D_interest = ['RightShoulder','RightShoulder.1','RightShoulder.2',\n",
    "                          'RightElbow', 'RightElbow.1','RightElbow.2',\n",
    "                          'RightHand','RightHand.1','RightHand.2',\n",
    "                          'LeftShoulder','LeftShoulder.1','LeftShoulder.2',\n",
    "                          'LeftElbow', 'LeftElbow.1', 'LeftElbow.2',\n",
    "                          'LeftHand','LeftHand.1','LeftHand.2']\n",
    "\n",
    "total_num_2Dcoordinates = len(mapping_numbers_variables)*2\n",
    "total_num_3Dcoordinates = len(mapping_numbers_variables)*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f15b1",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20af465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_nd_coordinates_array(coordinates_array, n): \n",
    "    m = 0\n",
    "    r = n\n",
    "    frame_coordinates = []\n",
    "    for j in range(0,int(len(coordinates_array)/n)):\n",
    "        frame_coordinates.append(coordinates_array[m:r])\n",
    "        m = r\n",
    "        r = r+n\n",
    "    return(np.array(frame_coordinates))\n",
    "\n",
    "def split_3_coordinates(values_array): \n",
    "    output = []\n",
    "    for i in range(0, len(values_array)):\n",
    "        m = 0\n",
    "        r = 3\n",
    "        frame_coordinates = []\n",
    "        for j in range(0,int(len(values_array[i])/3)):\n",
    "            frame_coordinates.append(values_array[i][m:r])\n",
    "            m = r\n",
    "            r = r+3\n",
    "        output.append(frame_coordinates)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13685078",
   "metadata": {},
   "source": [
    "### Fully connected residual NN testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdd8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\rlope\\anaconda3\\envs\\RBT_env\\lib\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: 2d_gt MPJPE[cm] obtained: 3.2796214666467463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\rlope\\anaconda3\\envs\\RBT_env\\lib\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: noise_lvl1 MPJPE[cm] obtained: 5.375939470474423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\rlope\\anaconda3\\envs\\RBT_env\\lib\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: noise_lvl1_with_synth_augmented MPJPE[cm] obtained: 6.617792317476876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\rlope\\anaconda3\\envs\\RBT_env\\lib\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: noise_lvl2 MPJPE[cm] obtained: 9.759071036243402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\rlope\\anaconda3\\envs\\RBT_env\\lib\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: noise_lvl3 MPJPE[cm] obtained: 12.87669832378278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\rlope\\anaconda3\\envs\\RBT_env\\lib\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: noise_lvl4 MPJPE[cm] obtained: 17.27310925949508\n"
     ]
    }
   ],
   "source": [
    "for model_folder in glob('../../solutions/Martinez/models/Non_Gravity/*'):\n",
    "    df_mocap_2D = pd.read_csv('../test_set/MartinezTestSet/2D_test_set_GT_data.csv').drop(columns=['Unnamed: 0'])\n",
    "    df_mocap_3D = pd.read_csv('../test_set/MartinezTestSet/3D_test_set_GT_data.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    model = keras.models.load_model(model_folder+'/model.h5')\n",
    "    scaler_2D = pickle.load(open(model_folder+'/scaler_2D.pkl','rb'))\n",
    "    scaler_3D = pickle.load(open(model_folder+'/scaler_3D.pkl','rb'))\n",
    "    \n",
    "    #Scaling dataset\n",
    "    df_mocap_2D = pd.DataFrame(scaler_2D.transform(np.array(df_mocap_2D)))\n",
    "    df_mocap_3D = pd.DataFrame(scaler_3D.transform(np.array(df_mocap_3D)))\n",
    "    \n",
    "    z_predicted = model.predict(np.array(df_mocap_2D))\n",
    "    df_pred_3d = pd.DataFrame(split_3_coordinates(z_predicted)).rename(columns=mapping_numbers_variables)\n",
    "    df_gt_3d = pd.DataFrame(split_3_coordinates(np.array(df_mocap_3D))).rename(columns=mapping_numbers_variables)\n",
    "    \n",
    "    #Compute the euclidean distances of each 3D predicted keypoint vs the ground truth and generate a dataframe with the results.\n",
    "    all_distances = []\n",
    "    for keypoint in list(mapping_numbers_variables.values()):\n",
    "        keypoint_distances = []\n",
    "        for i in range(0,len(df_gt_3d[keypoint])):    \n",
    "            keypoint_distances.append(distance.euclidean(df_gt_3d[keypoint][i], df_pred_3d[keypoint][i]))\n",
    "        all_distances.append(keypoint_distances)\n",
    "\n",
    "    df_PJPE = pd.DataFrame(all_distances).T\n",
    "    means = []\n",
    "    for column in list(df_PJPE.columns):\n",
    "        means.append(df_PJPE[column].mean())\n",
    "\n",
    "    mpjpe = sum(means)/len(df_PJPE.columns)\n",
    "    print('Model analyzed: '+ str(model_folder.split('\\\\')[-1])+ ' MPJPE[cm] obtained: ' +str(mpjpe*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e28e71",
   "metadata": {},
   "source": [
    "### Sequence2Sequence testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1089d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinic_K2\\anaconda3\\envs\\RGSpipe\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model analyzed: 2d_gt MPJPE[cm] obtained: 5.7599845201857285\n",
      "Model analyzed: noise_lvl1 MPJPE[cm] obtained: 6.756606996280867\n",
      "Model analyzed: noise_lvl2 MPJPE[cm] obtained: 8.253439010824492\n",
      "Model analyzed: noise_lvl3 MPJPE[cm] obtained: 9.843918799330421\n",
      "Model analyzed: noise_lvl4 MPJPE[cm] obtained: 11.484753979601898\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros([6590, 5, 12])\n",
    "arr2 = np.zeros([6590,5,18])\n",
    "\n",
    "for model_folder in glob('../../solutions/LSTM/models/Non_Gravity/*'):\n",
    "    \n",
    "    X_loaded_arr = np.loadtxt(\"../test_set/LSTMTestSet/2D_GT_testSet_LSTM.txt\")\n",
    "    X_load_original_arr = X_loaded_arr.reshape(X_loaded_arr.shape[0], X_loaded_arr.shape[1] // arr.shape[2], arr.shape[2])\n",
    "    \n",
    "    y_loaded_arr = np.loadtxt(\"../test_set/LSTMTestSet/3D_GT_testSet_LSTM.txt\")\n",
    "    y_load_original_arr = y_loaded_arr.reshape(y_loaded_arr.shape[0], y_loaded_arr.shape[1] // arr2.shape[2], arr2.shape[2])\n",
    "    \n",
    "\n",
    "    model = keras.models.load_model(model_folder+'/model.h5')\n",
    "    scaler_2D = pickle.load(open(model_folder+'/scaler_2D.pkl','rb'))\n",
    "    scaler_3D = pickle.load(open(model_folder+'/scaler_3D.pkl','rb'))\n",
    "   \n",
    "    y_predicted = model.predict(np.array(X_load_original_arr))\n",
    "    \n",
    "    all_distances = []\n",
    "    for i in range(0,y_load_original_arr.shape[0]):\n",
    "        gt_splitted = split_nd_coordinates_array(y_load_original_arr[i][4],3)\n",
    "        pred_splitted = split_nd_coordinates_array(y_predicted[i][4],3)\n",
    "        keypoints_distances = []\n",
    "        for j in range(0,pred_splitted.shape[0]):\n",
    "            keypoints_distances.append(distance.euclidean(gt_splitted[j], pred_splitted[j]))\n",
    "        all_distances.append(keypoints_distances)\n",
    "\n",
    "    df_PJPE = pd.DataFrame(all_distances).rename(columns=mapping_numbers_variables)\n",
    "    \n",
    "    means = []\n",
    "    for column in list(df_PJPE.columns):\n",
    "        means.append(df_PJPE[column].mean())\n",
    "\n",
    "    mpjpe = sum(means)/len(df_PJPE.columns)\n",
    "    print('Model analyzed: '+ str(model_folder.split('\\\\')[-1])+ ' MPJPE[cm] obtained: ' +str(mpjpe*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
